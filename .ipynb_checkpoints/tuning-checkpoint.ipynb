{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2l = tf.keras.applications.EfficientNetV2L(\n",
    "        include_top=True,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        classifier_activation=\"softmax\",\n",
    "        include_preprocessing=True,\n",
    "    )\n",
    "\n",
    "    v2m = tf.keras.applications.EfficientNetV2L(\n",
    "        include_top=True,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        classifier_activation=\"softmax\",\n",
    "        include_preprocessing=True,\n",
    "    )\n",
    "\n",
    "    cxl = tf.keras.applications.ConvNeXtXLarge(\n",
    "        model_name=\"convnext_xlarge\",\n",
    "        include_top=True,\n",
    "        include_preprocessing=True,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        classifier_activation=\"softmax\",\n",
    "    )\n",
    "\n",
    "    r50 = tf.keras.applications.ResNet50(\n",
    "        include_top=True,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    vgg16 = tf.keras.applications.VGG16(\n",
    "        include_top=True,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        classifier_activation=\"softmax\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Tuning\n",
    "\n",
    "Models to Cover \n",
    "1. v2l\n",
    "2. v2m\n",
    "3. cxm\n",
    "4. r50\n",
    "5. vgg16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset=tf.data.TFRecordDataset(['birds-vs-squirrels-train.tfrecords'])\n",
    "feature_description={'image':tf.io.FixedLenFeature([],tf.string),\n",
    "                     'label':tf.io.FixedLenFeature([],tf.int64)\n",
    "                    }\n",
    "\n",
    "def parse_examples(serialized_examples):\n",
    "    examples=tf.io.parse_example(serialized_examples,feature_description)\n",
    "    targets=examples.pop('label')\n",
    "    images=tf.image.resize_with_pad(tf.cast(tf.io.decode_jpeg(\n",
    "    examples['image'],channels=3),tf.float32),299,299)\n",
    "    return images, targets\n",
    "    \n",
    "#you can edit batch size and num_parallel calls below based on your architecture\n",
    "dataset=raw_dataset.map(parse_examples,num_parallel_calls=16).batch(128)\n",
    "# run through your provided preprocess method\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label, model_input_size):\n",
    "\n",
    "    image = tf.image_resize(image, model_input_size)\n",
    "    tf.keras.applications.EfficientNetV2L.preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2l_dataset=dataset.map(preprocess,num_parallel_calls=16).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(v2l_dataset))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
