{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 01:02:52.404706: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-11 01:02:52.404763: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-11 01:02:52.404786: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-11 01:02:52.414771: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mlp import generate_mlp\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Bayesian Optimization Libraries for hyperparameter tuning.\n",
    "import optuna\n",
    "from numba import cuda\n",
    "import gc\n",
    "\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 256, 256\n",
    "classes = 3\n",
    "epochs = 1\n",
    "hyp_calls = 30\n",
    "\n",
    "# Preprocessing stuff\n",
    "image_tup = (height, width)\n",
    "batch_size = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Tuning\n",
    "\n",
    "Models to Cover \n",
    "1. v2l\n",
    "2. v2m\n",
    "3. cxm\n",
    "4. r50\n",
    "5. vgg16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset, train_size_ratio=0.8, shuffle_buffer_size=1000):\n",
    "\n",
    "    dataset_size = sum(1 for _ in dataset)\n",
    "\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    train_size = int(train_size_ratio * dataset_size)\n",
    "\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size)\n",
    "\n",
    "    return train_dataset, val_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_examples(serialized_examples):\n",
    "    feature_description={'image':tf.io.FixedLenFeature([],tf.string),\n",
    "                         'label':tf.io.FixedLenFeature([],tf.int64)}\n",
    "    examples=tf.io.parse_example(serialized_examples, feature_description)\n",
    "    labels=examples.pop('label')\n",
    "    labels = tf.one_hot(labels, depth=classes) \n",
    "    images=tf.image.resize_with_pad(tf.cast(tf.io.decode_jpeg(examples['image'],channels=3),tf.float32),299,299)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def preprocess(image, label):\n",
    "        print(type(image))\n",
    "        print(image)\n",
    "    \n",
    "        image = tf.image.resize(image, image_tup)\n",
    "        tf.keras.applications.efficientnet_v2.preprocess_input(image)\n",
    "    \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    raw_dataset_train= tf.data.TFRecordDataset(['birds-vs-squirrels-train.tfrecords'])\n",
    "    raw_dataset_valid = tf.data.TFRecordDataset(['birds-vs-squirrels-validation.tfrecords'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_base, test_base = train_test_split(raw_dataset_train, 0.8, shuffle_buffer_size=10000)\n",
    "    \n",
    "    train_base = train_base.map(parse_examples, num_parallel_calls=16)\n",
    "    test_base = test_base.map(parse_examples, num_parallel_calls=16)\n",
    "    val_base = raw_dataset_valid.map(parse_examples, num_parallel_calls=16)\n",
    "\n",
    "    val_X = []\n",
    "    val_y = []\n",
    "    \n",
    "    for image, label in val_base:\n",
    "        val_X.append(image.numpy())  # Convert to numpy array\n",
    "        val_y.append(label.numpy())\n",
    "    \n",
    "    val_x = np.array(val_X)\n",
    "    val_y = np.array(val_y)\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  \n",
    "        patience=5, \n",
    "        min_delta=0.01,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    train = train_base.map(preprocess, num_parallel_calls=-1)\n",
    "    test = test_base.map(preprocess, num_parallel_calls=-1)\n",
    "    valid = val_base.map(preprocess, num_parallel_calls=-1)\n",
    "    \n",
    "    train = train.batch(batch_size)\n",
    "    test = test.batch(batch_size)\n",
    "    valid = valid.batch(batch_size)\n",
    "    \n",
    "    input_shape = (height, width, 3)\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    v2l = tf.keras.applications.EfficientNetV2L(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=(height, width, classes),\n",
    "        pooling=None,\n",
    "        classes=classes,\n",
    "        classifier_activation=\"softmax\",\n",
    "        include_preprocessing=True,\n",
    "    )\n",
    "\n",
    "    r50 = tf.keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=(height, width, classes),\n",
    "        pooling=None,\n",
    "        classes=3,\n",
    "        )\n",
    "\n",
    "    vgg16 = tf.keras.applications.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=(height, width, classes),\n",
    "        pooling=None,\n",
    "        classes=classes,\n",
    "        classifier_activation=\"softmax\",\n",
    "        )\n",
    "    cxl = tf.keras.applications.ConvNeXtXLarge(\n",
    "        model_name=\"convnext_xlarge\",\n",
    "        include_top=False,\n",
    "        include_preprocessing=True,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=(height, width, classes),\n",
    "        pooling=None,\n",
    "        classes=classes,\n",
    "        classifier_activation=\"softmax\",\n",
    "    )\n",
    "\n",
    "    v2m = tf.keras.applications.EfficientNetV2L(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=None,\n",
    "            input_shape=(height, width, classes),\n",
    "            pooling=None,\n",
    "            classes=classes,\n",
    "            classifier_activation=\"softmax\",\n",
    "            include_preprocessing=True,\n",
    "        )\n",
    "\n",
    "    return train, test, valid, val_x, val_y, v2l, vgg16, v2m, r50, cxl, inputs, early_stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_from_str(base_model_str, v2l, vgg16, v2m, r50, cxl):\n",
    "    if base_model_str == 'v2l':\n",
    "        return v2l\n",
    "    elif base_model_str == 'vgg16':\n",
    "        return vgg16\n",
    "    elif base_model_str == 'v2m':\n",
    "        return v2m\n",
    "    elif base_model_str == 'r50':\n",
    "        return r50\n",
    "    elif base_model_str == 'cxl':\n",
    "        return cxl\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model string: {base_model_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer:str, base_model:str, activation, init_neurons, num_layers, scaling_factor, dropout_rate, learning_rate, v2l, vgg16, v2m, r50, cxl, inputs):\n",
    "    \n",
    "    base_model = get_model_from_str(base_model, v2l, vgg16, v2m, r50, cxl)\n",
    "    base_model.trainable = False\n",
    "    x = base_model(inputs, training=False) # Inputs is defined in section above. \n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Define your custom top layer\n",
    "    top_layer = generate_mlp(num_layers=num_layers, \n",
    "                             initial_neurons=init_neurons, \n",
    "                             output_classes=classes, \n",
    "                             dropout_rate=dropout_rate, \n",
    "                             activation_function=activation,\n",
    "                             scaling_factor=scaling_factor)\n",
    "    \n",
    "    x = top_layer(x)\n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Optuna suggests the parameters\n",
    "    optimizer = trial.suggest_categorical('optimizer', ['adam', 'sgd'])\n",
    "    base_model = trial.suggest_categorical('base_model', ['r50', 'v2l', 'vgg16', 'v2m',  'cxl'])\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid'])\n",
    "    init_neurons = trial.suggest_int('init_neurons', 32, 1028)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 10)\n",
    "    scaling_factor = trial.suggest_float('scaling_factor', 0.01, 0.99)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.01, 0.99)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n",
    "\n",
    "    train, test, valid, val_x, val_y, v2l, vgg16, v2m, r50, cxl, inputs, early_stopping = load_data() \n",
    "\n",
    "    model = create_model(optimizer, base_model, activation, init_neurons, num_layers, scaling_factor, dropout_rate, learning_rate, v2l, vgg16, v2m, r50, cxl, inputs)\n",
    "    \n",
    "    # Assume you have training data (X_train, y_train)\n",
    "    model.fit(train, epochs=epochs, batch_size = batch_size, validation_data=test, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    acc = model.evaluate(val_x, val_y, verbose=0) \n",
    "    tf.keras.backend.clear_session()\n",
    "    del model, v2l, vgg16, v2m, r50, cxl, train, test, valid\n",
    "    gc.collect()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    return -acc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-11 01:02:55,385] A new study created in memory with name: no-name-bafbc748-04ea-4dce-8ecc-e3226d7c1fcb\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46292/473620576.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n",
      "2023-11-11 01:02:55.523411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-11 01:02:55.530005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-11 01:02:55.530063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-11 01:02:55.531932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-11 01:02:55.531970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-11 01:02:55.531987: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-11 01:02:56.488396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-11 01:02:56.488519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-11 01:02:56.488529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-11 01:02:56.488560: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-11 01:02:56.488578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9364 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
      "Tensor(\"args_0:0\", shape=(299, 299, 3), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
      "Tensor(\"args_0:0\", shape=(299, 299, 3), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
      "Tensor(\"args_0:0\", shape=(299, 299, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 01:03:35.466128: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-11 01:03:38.622045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-11 01:03:39.560030: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-11 01:03:40.069372: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd01c6f84b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-11 01:03:40.069406: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2023-11-11 01:03:40.441884: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 180s 248ms/step - loss: 0.7398 - accuracy: 0.7215 - val_loss: 0.3924 - val_accuracy: 0.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 01:06:26.896976: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2718505608 exceeds 10% of free system memory.\n",
      "2023-11-11 01:06:29.529517: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2718505608 exceeds 10% of free system memory.\n",
      "[I 2023-11-11 01:07:38,445] Trial 0 finished with value: -0.9617205858230591 and parameters: {'optimizer': 'sgd', 'base_model': 'cxl', 'activation': 'tanh', 'init_neurons': 945, 'num_layers': 5, 'scaling_factor': 0.7453602465605936, 'dropout_rate': 0.0964543852992191, 'learning_rate': 0.00010753396664346617}. Best is trial 0 with value: -0.9617205858230591.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=hyp_calls, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Best objective value achieved\n",
    "best_value = study.best_value\n",
    "print(\"Best Objective Value:\", best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all trials\n",
    "for trial in study.trials:\n",
    "    print(\"Trial Number:\", trial.number)\n",
    "    print(\"Params:\", trial.params)\n",
    "    print(\"Value:\", trial.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "plot_optimization_history(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
